# -*- coding: utf-8 -*-
"""Fraud_Detection_Using_MongoDB_and_Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xx8aSAgO9gQjUjZpcSxGpvgDzuJwfMpK
"""

!pip install pymongo

#install the necessary libraries
import pymongo
import pandas as pd
import logging

#extract data function
def extract_data(call_logs_csv, billing_system_csv):
  calls_df = pd.read_csv(call_logs_csv)
  billing_df = pd.read_csv(billing_system_csv)
  #merge data
  """  The 2 data sets do not have any common columns. 
  We will work with the following assumptions:
    1. there's one customer txn per day
    2. call date and transaction date are the same day for each customer
  """
  # create common column name
  calls_df = calls_df.rename(columns={"call_date": "date"})
  billing_df = billing_df.rename(columns={"transaction_date": "date"})
  #merge data on date column
  merged_df = pd.merge(calls_df, billing_df, on=['date'])
  
  # Convert call duration to minutes for easier analysis
  merged_df['duration_minutes'] = merged_df['call_duration'] / 60
  # Use Python logging module to log errors and activities
  logger = logging.getLogger(__name__)
  logger.info("Data extraction completed.")

  return merged_df

#data Transformation function
def transform_data(df):
    # handling missing values & duplicates
    df = df.dropna()
    df = df.drop_duplicates()

    # Group and aggregate the data
    transformed_data = df.groupby(['customer_id']).agg(
        total_duration=('duration_minutes', 'sum'),
        total_calls=('call_type', 'count')
    ).reset_index()

    # Identify patterns in the data
    transformed_data['is_fraudulent'] = (transformed_data['total_duration'] > 300) & (transformed_data['total_calls'] > 100)

    # Use data compression techniques to optimize performance
    transformed_data = transformed_data.astype({'customer_id': 'int32', 'is_fraudulent': 'bool'})

    # Use Python logging module to log errors and activities
    logger = logging.getLogger(__name__)
    logger.info("Data transformation completed.")

    return transformed_data
  
#load data to  MongoDB
def load_data(transformed_data):
  conn_str = "mongodb+srv://Lillian_Miiri:OHClGxsRPfMBIc4y@moringade.vpsdfqr.mongodb.net/?retryWrites=true&w=majority"
  client = pymongo.MongoClient(conn_str,ssl=True)
  #select a database and collection
  db = client['Fraud']
  collection = db['fraud_detection']
  
  # Create indexes on the collection
  collection.create_index([('customer_id', 1)])
  collection.create_index([('is_fraudulent', 1)])
  
  # Use bulk inserts to optimize performance
  bulk_data = data.to_dict(orient='records')
  collection.insert_many(bulk_data)
  
  # Use the write concern option to ensure that data is written to disk
  collection.acknowledge_writes(w=1, j=True)

  # Use Python logging module to log errors and activities
  logger = logging.getLogger(__name__)
  logger.info("Data loading completed.")

# Example usage
if __name__ == '__main__':
    # Set up logging
    logging.basicConfig(level=logging.INFO)
    
    #file locations
    call_logs_csv = 'call_logs.csv'
    billing_system_csv = 'billing_systems.csv'

    # Extract data
    data = extract_data(call_logs_csv, billing_system_csv)
    # Transform data
    transformed_data = transform_data(data)
    
    # Load data into MongoDB
    load_data(transformed_data)